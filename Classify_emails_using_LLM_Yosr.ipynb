{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pandas transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88HmcYznVwTl",
        "outputId": "c2928e9a-0175-46a5-cd07-176cb4cafc48"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('/content/spam.csv', encoding='latin1')\n",
        "    print(\"Dataset loaded successfully. Here's a preview:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nDataset info:\")\n",
        "    print(df.info())\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: spam.csv not found. Make sure the file is in the same directory as your script.\")\n",
        "    # Exit or handle the error appropriately if the file isn't found\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g5Ubim9V5cv",
        "outputId": "935a7986-bb3b-42ea-a798-26d247efe5a5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully. Here's a preview:\n",
            "                                                text target\n",
            "0  Go until jurong point, crazy.. Available only ...    ham\n",
            "1                      Ok lar... Joking wif u oni...    ham\n",
            "2  Free entry in 2 a wkly comp to win FA Cup fina...   spam\n",
            "3  U dun say so early hor... U c already then say...    ham\n",
            "4  Nah I don't think he goes to usf, he lives aro...    ham\n",
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    5572 non-null   object\n",
            " 1   target  5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "try:\n",
        "    classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "    print(\"\\nLLM (text-classification pipeline) loaded successfully.\")\n",
        "    print(\"Using model:\", classifier.model.name_or_path)\n",
        "except Exception as e:\n",
        "    print(f\"\\nError loading LLM: {e}\")\n",
        "    print(\"Please check your internet connection or try a different model name.\")\n",
        "    exit()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsCf33vHV-XU",
        "outputId": "0db1a0ea-5a22-49e1-95c4-3b4505826d0a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LLM (text-classification pipeline) loaded successfully.\n",
            "Using model: distilbert-base-uncased-finetuned-sst-2-english\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to classify a batch of emails using the loaded LLM\n",
        "def classify_email_batch(texts):\n",
        "    predicted_labels = []\n",
        "    # Loop through each text in the batch\n",
        "    for text in texts:\n",
        "        # Prompt Engineering\n",
        "        prompt = f\"Classify the following email as 'ham' or 'spam'. Respond with only 'ham' or 'spam'.\\n\\nEmail: \\\"{text}\\\"\\nClassification:\"\n",
        "\n",
        "        try:\n",
        "            # Step 3b: Perform LLM inference\n",
        "            llm_output = classifier(prompt)[0]['label']\n",
        "\n",
        "            # Step 3c: Map LLM output to 'ham' or 'spam' (if necessary)\n",
        "\n",
        "            if llm_output == 'POSITIVE': # Assuming 'POSITIVE' might relate to ham (or spam depending on context)\n",
        "                final_label = 'ham'\n",
        "            elif llm_output == 'NEGATIVE': # Assuming 'NEGATIVE' might relate to spam (or ham)\n",
        "                final_label = 'spam'\n",
        "            else:\n",
        "\n",
        "                final_label = llm_output.lower()\n",
        "\n",
        "            predicted_labels.append(final_label)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error classifying email: '{text[:50]}...' - {e}\")\n",
        "            predicted_labels.append(\"error_in_classification\")\n",
        "    return predicted_labels\n",
        "\n",
        "print(\"\\nBatch classification function defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRMzNxXaWBqP",
        "outputId": "de1d4462-ac2a-4b1d-8fae-67fd1ce7bb85"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch classification function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a list to store all predicted targets\n",
        "all_predicted_targets = []\n",
        "\n",
        "# Define batch size (adjust based on your system's memory and LLM's capacity)\n",
        "batch_size = 1000 # Start with a small batch size, e.g., 1000 or 20000, then increase if stable.\n",
        "\n",
        "print(f\"\\nStarting batch processing with batch size: {batch_size}\")\n",
        "print(f\"Total emails to process: {len(df)}\")\n",
        "\n",
        "# Process the DataFrame in batches\n",
        "for i in range(0, len(df), batch_size):\n",
        "    # Get the current batch of texts\n",
        "    batch_df = df.iloc[i:i + batch_size]\n",
        "    batch_texts = batch_df['text'].tolist()\n",
        "\n",
        "    if not batch_texts: # Skip if batch is empty (can happen at the very end)\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing emails {i} to {min(i + batch_size, len(df))}...\")\n",
        "\n",
        "    # Get predictions for the current batch using your LLM\n",
        "    predicted_labels = classify_email_batch(batch_texts)\n",
        "\n",
        "    # Extend the main list of predictions\n",
        "    all_predicted_targets.extend(predicted_labels)\n",
        "\n",
        "print(\"\\nBatch processing complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXv0mMZRaUll",
        "outputId": "6dcabb9c-f493-48f9-e4d7-f85a739b9d35"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting batch processing with batch size: 1000\n",
            "Total emails to process: 5572\n",
            "Processing emails 0 to 1000...\n",
            "Processing emails 1000 to 2000...\n",
            "Processing emails 2000 to 3000...\n",
            "Processing emails 3000 to 4000...\n",
            "Processing emails 4000 to 5000...\n",
            "Processing emails 5000 to 5572...\n",
            "\n",
            "Batch processing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the predicted targets back to the original DataFrame\n",
        "if len(all_predicted_targets) == len(df):\n",
        "    df['predicted_target'] = all_predicted_targets\n",
        "    print(\"\\nPredicted targets added to DataFrame. Here's a sample:\")\n",
        "    print(df[['text', 'target', 'predicted_target']].head(10))\n",
        "\n",
        "    # Basic Evaluation (Optional, but recommended)\n",
        "    from sklearn.metrics import accuracy_score, classification_report\n",
        "    df['target_normalized'] = df['target'].apply(lambda x: x.strip().lower())\n",
        "    df['predicted_target_normalized'] = df['predicted_target'].apply(lambda x: x.strip().lower())\n",
        "\n",
        "    # Filter out any 'error_in_classification'\n",
        "    valid_predictions_df = df[df['predicted_target_normalized'] != 'error_in_classification']\n",
        "\n",
        "    if not valid_predictions_df.empty:\n",
        "        true_labels = valid_predictions_df['target_normalized']\n",
        "        pred_labels = valid_predictions_df['predicted_target_normalized']\n",
        "\n",
        "        # Get unique labels from both true and predicted sets for consistent reporting\n",
        "        all_labels = sorted(list(set(true_labels.tolist() + pred_labels.tolist())))\n",
        "\n",
        "        print(f\"\\nAccuracy: {accuracy_score(true_labels, pred_labels):.4f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(true_labels, pred_labels, labels=all_labels, zero_division=0))\n",
        "    else:\n",
        "        print(\"\\nNo valid predictions to evaluate.\")\n",
        "\n",
        "else:\n",
        "    print(f\"Mismatch in number of predictions ({len(all_predicted_targets)}) and emails ({len(df)}).\")\n",
        "    print(\"Something went wrong during batch processing.\")\n",
        "\n",
        "print(\"\\nPractical Exercise 1: Email classification setup complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY4mfuf0dFNE",
        "outputId": "053723a6-f11e-4861-81b9-80564cd8c649"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted targets added to DataFrame. Here's a sample:\n",
            "                                                text target predicted_target\n",
            "0  Go until jurong point, crazy.. Available only ...    ham             spam\n",
            "1                      Ok lar... Joking wif u oni...    ham             spam\n",
            "2  Free entry in 2 a wkly comp to win FA Cup fina...   spam             spam\n",
            "3  U dun say so early hor... U c already then say...    ham             spam\n",
            "4  Nah I don't think he goes to usf, he lives aro...    ham             spam\n",
            "5  FreeMsg Hey there darling it's been 3 week's n...   spam             spam\n",
            "6  Even my brother is not like to speak with me. ...    ham             spam\n",
            "7  As per your request 'Melle Melle (Oru Minnamin...    ham             spam\n",
            "8  WINNER!! As a valued network customer you have...   spam             spam\n",
            "9  Had your mobile 11 months or more? U R entitle...   spam             spam\n",
            "\n",
            "Accuracy: 0.1637\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.91      0.04      0.07      4825\n",
            "        spam       0.14      0.98      0.24       747\n",
            "\n",
            "    accuracy                           0.16      5572\n",
            "   macro avg       0.52      0.51      0.16      5572\n",
            "weighted avg       0.81      0.16      0.10      5572\n",
            "\n",
            "\n",
            "Practical Exercise 1: Email classification setup complete.\n"
          ]
        }
      ]
    }
  ]
}